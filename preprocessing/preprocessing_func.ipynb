{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from collections import Counter\n",
    "from glob import glob\n",
    "\n",
    "import mne\n",
    "from mne_nirs.io.snirf import write_raw_snirf\n",
    "from mne_nirs.io import fold\n",
    "import mne_nirs\n",
    "from mne_bids import write_raw_bids, BIDSPath, read_raw_bids\n",
    "import matplotlib.pyplot as plt\n",
    "from mne_nirs.experimental_design import make_first_level_design_matrix\n",
    "from mne.preprocessing.nirs import (optical_density,\n",
    "                                    temporal_derivative_distribution_repair)\n",
    "from nilearn.plotting import plot_design_matrix\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA, FastICA\n",
    "from mne.decoding import UnsupervisedSpatialFilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found subjects: ['01', '010', '011', '012', '02', '03', '04', '05', '06', '07', '08', '09']\n",
      "Found sessions: ['01', '02']\n",
      "All 12 subject came for 2 sessions.\n"
     ]
    }
   ],
   "source": [
    "root_bids = r'C:\\Datasets\\Test-retest study\\bids_dataset'  # Replace with the path to your data\n",
    "root_nirx = r'C:\\Datasets\\Test-retest study\\sourcedata\\sub-05\\ses-01\\nirs'\n",
    "task = \"auditory\"        # Set to whatever the name of your experiment is\n",
    "stimulus_duration = {'Control': 5, 'Noise': 5, 'Speech': 5.25}\n",
    "trigger_info = {'1.0': 'Control',\n",
    "                '2.0': 'Noise',\n",
    "                '3.0': 'Speech',\n",
    "                '4.0': 'XStop_break', # start of break?\n",
    "                '5.0': 'XStart_break'}   # end of break?\n",
    "\n",
    "subject_dirs = glob(os.path.join(root_bids, \"sub-*\"))\n",
    "subjects = [subject_dir.split(\"-\")[-1] for subject_dir in subject_dirs] # [\"01\",\"02\",...]\n",
    "\n",
    "ses_list = np.array([])\n",
    "for folder in subject_dirs:\n",
    "    ses_list = np.append(ses_list,np.array([ses for ses in os.listdir(folder)]))\n",
    "ses_dict = dict(Counter(ses_list))\n",
    "# Check if all participants came the same number of times\n",
    "sessions = list(ses_dict.keys())\n",
    "sessions =[ses.split(\"-\")[-1] for ses in sessions] # [\"01\",\"02\",...]\n",
    "complete_sub_ses = all([value == len(subjects) for value in ses_dict.values()])\n",
    "\n",
    "print(f\"Found subjects: {subjects}\")\n",
    "print(f\"Found sessions: {sessions}\")\n",
    "if complete_sub_ses:\n",
    "    print(f\"All {len(subjects)} subject came for {len(sessions)} sessions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing subject 05, session 01...\n",
      "Loading raw NIRS data from BIDS dataset format\n",
      "Reading 0 ... 8666  =      0.000 ...  1663.872 secs...\n",
      "Extracting event timings...\n",
      "Used Annotations descriptions: [np.str_('Control'), np.str_('Noise'), np.str_('Speech'), np.str_('XStart_break'), np.str_('XStop_break')]\n",
      "Used Annotations descriptions: [np.str_('XStart_break'), np.str_('XStop_break')]\n",
      "Original duration: 1663.87 seconds\n",
      "Cropping the breaks from the dataset...\n",
      "Cropped duration: 1262.59 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'epochs = mne_nirs.Epochs(\\n    raw_intensity_cropped, AllEvents, event_id=events_id,\\n)'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## PRE-PROCESSING PIPELINE\n",
    "# Describe steps?\n",
    "\n",
    "subject = '05'\n",
    "session = '01'\n",
    "\n",
    "data_path = root_bids\n",
    "\n",
    "print(f\"Processing subject {subject}, session {session}...\")\n",
    "#os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "# Create path to file based on experiment info\n",
    "bids_path = BIDSPath(subject=subject,\n",
    "                        session=session,\n",
    "                        task=task,\n",
    "                        root=data_path,\n",
    "                        datatype=\"nirs\",\n",
    "                        suffix=\"nirs\",\n",
    "                        extension=\".snirf\")\n",
    "\n",
    "# Load data\n",
    "print(\"Loading raw NIRS data from BIDS dataset format\")\n",
    "raw_intensity = read_raw_bids(bids_path=bids_path, verbose=False)\n",
    "raw_intensity.load_data()\n",
    "\n",
    "# Set durations\n",
    "raw_intensity.annotations.set_durations({'Control': 5, 'Noise': 5, 'Speech': 5.25})\n",
    "\n",
    "# Get event timings\n",
    "print(\"Extracting event timings...\")\n",
    "AllEvents, event_id = mne.events_from_annotations(raw_intensity)\n",
    "Breaks, _ = mne.events_from_annotations(raw_intensity, {'XStop_break': 4, 'XStart_break': 5})\n",
    "# Get Breaks from index to time stamps\n",
    "Breaks = Breaks[:, 0] / raw_intensity.info['sfreq']\n",
    "LastEvent = AllEvents[-1, 0] / raw_intensity.info['sfreq']\n",
    "\n",
    "if len(Breaks) % 2 == 0:\n",
    "    raise ValueError(\"Breaks array should have an odd number of elements.\")\n",
    "\n",
    "# Compute total experiment duration with breaks\n",
    "original_duration = raw_intensity.times[-1] - raw_intensity.times[0]\n",
    "print(f\"Original duration: {original_duration:.2f} seconds\")\n",
    "\n",
    "# Cropping dataset\n",
    "print(\"Cropping the breaks from the dataset...\")\n",
    "cropped_intensity = raw_intensity.copy().crop(Breaks[0], Breaks[1]) # block 1 in between break\n",
    "# Crop and append blocks 2, 3 and 4\n",
    "for j in range(2, len(Breaks) - 1, 2):\n",
    "    block = raw_intensity.copy().crop(Breaks[j], Breaks[j + 1]) \n",
    "    cropped_intensity.append(block)\n",
    "cropped_intensity.append(raw_intensity.copy().crop(Breaks[-1], LastEvent + 15.25)) # why 15.25?\n",
    "\n",
    "cropped_duration = cropped_intensity.times[-1] - cropped_intensity.times[0]\n",
    "print(f\"Cropped duration: {cropped_duration:.2f} seconds\")\n",
    "\n",
    "if cropped_duration >= original_duration:\n",
    "    print(f\"WARNING: Cropping did not reduce duration for {subject} - {session}!\")\n",
    "\n",
    "raw_intensity_cropped = cropped_intensity.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing break annotations for the orginal raw...\n",
      "Removing break annotations for the cropped raw...\n"
     ]
    }
   ],
   "source": [
    "# Remove break annotations\n",
    "print(\"Removing break annotations for the orginal raw...\")\n",
    "raw_intensity.annotations.delete(np.where(\n",
    "    (raw_intensity.annotations.description == 'XStart_break') | \n",
    "    (raw_intensity.annotations.description == 'XStop_break') | \n",
    "    (raw_intensity.annotations.description == 'BAD boundary') | \n",
    "    (raw_intensity.annotations.description == 'EDGE boundary')\n",
    "    )[0])\n",
    "\n",
    "print(\"Removing break annotations for the cropped raw...\")\n",
    "raw_intensity_cropped.annotations.delete(np.where(\n",
    "    (raw_intensity_cropped.annotations.description == 'XStart_break') | \n",
    "    (raw_intensity_cropped.annotations.description == 'XStop_break') | \n",
    "    (raw_intensity_cropped.annotations.description == 'BAD boundary') | \n",
    "    (raw_intensity_cropped.annotations.description == 'EDGE boundary')\n",
    "    )[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting to optical density...\n"
     ]
    }
   ],
   "source": [
    "# Optical density \n",
    "print(\"Converting to optical density...\")\n",
    "cropped_od = optical_density(raw_intensity_cropped)\n",
    "original_od= optical_density(raw_intensity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project onto PCA before converting back to optical density\n",
    "pca = UnsupervisedSpatialFilter(PCA(30), average=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Motion artifact correction\n",
    "print(\"Applying 'Temporal Derivative Distribution Repair' motion artefact correction...\")\n",
    "cropped_corrected_od = temporal_derivative_distribution_repair(cropped_od)\n",
    "original_corrected_od = temporal_derivative_distribution_repair(original_od)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def signal_quality_single_subject(data_path, save_path, task, subject, session):\n",
    "    print(f\"Processing subject {subject}, session {session}...\")\n",
    "    #os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "    # Create path to file based on experiment info\n",
    "    bids_path = BIDSPath(subject=subject,\n",
    "                            session=session,\n",
    "                            task=task,\n",
    "                            root=data_path,\n",
    "                            datatype=\"nirs\",\n",
    "                            suffix=\"nirs\",\n",
    "                            extension=\".snirf\")\n",
    "\n",
    "    # Load data\n",
    "    print(\"Loading raw NIRS data from BIDS dataset format\")\n",
    "    raw_intensity = read_raw_bids(bids_path=bids_path, verbose=False)\n",
    "    raw_intensity.load_data()\n",
    "\n",
    "    # Set durations\n",
    "    raw_intensity.annotations.set_durations({'Control': 5, 'Noise': 5, 'Speech': 5.25})\n",
    "\n",
    "    # Get event timings\n",
    "    print(\"Extracting event timings...\")\n",
    "    AllEvents, _ = mne.events_from_annotations(raw_intensity)\n",
    "    Breaks, _ = mne.events_from_annotations(raw_intensity, {'XStop_break': 4, 'XStart_break': 5})\n",
    "    # Get Breaks from index to time stamps\n",
    "    Breaks = Breaks[:, 0] / raw_intensity.info['sfreq']\n",
    "    LastEvent = AllEvents[-1, 0] / raw_intensity.info['sfreq']\n",
    "\n",
    "    if len(Breaks) % 2 == 0:\n",
    "        raise ValueError(\"Breaks array should have an odd number of elements.\")\n",
    "\n",
    "    # Compute total experiment duration with breaks\n",
    "    original_duration = raw_intensity.times[-1] - raw_intensity.times[0]\n",
    "    print(f\"Original duration: {original_duration:.2f} seconds\")\n",
    "\n",
    "    # Cropping dataset\n",
    "    print(\"Cropping the breaks from the dataset...\")\n",
    "    cropped_intensity = raw_intensity.copy().crop(Breaks[0], Breaks[1]) # block 1 in between break\n",
    "    # Crop and append blocks 2, 3 and 4\n",
    "    for j in range(2, len(Breaks) - 1, 2):\n",
    "        block = raw_intensity.copy().crop(Breaks[j], Breaks[j + 1]) \n",
    "        cropped_intensity.append(block)\n",
    "    cropped_intensity.append(raw_intensity.copy().crop(Breaks[-1], LastEvent + 15.25)) # why 15.25?\n",
    "\n",
    "    cropped_duration = cropped_intensity.times[-1] - cropped_intensity.times[0]\n",
    "    print(f\"Cropped duration: {cropped_duration:.2f} seconds\")\n",
    "\n",
    "    if cropped_duration >= original_duration:\n",
    "        print(f\"WARNING: Cropping did not reduce duration for {subject} - {session}!\")\n",
    "\n",
    "    raw_intensity_cropped = cropped_intensity.copy()\n",
    "\n",
    "    # Remove break annotations\n",
    "    print(\"Removing break annotations for the orginal raw...\")\n",
    "    raw_intensity.annotations.delete(np.where(\n",
    "        (raw_intensity.annotations.description == 'XStart_break') | \n",
    "        (raw_intensity.annotations.description == 'XStop_break') | \n",
    "        (raw_intensity.annotations.description == 'BAD boundary') | \n",
    "        (raw_intensity.annotations.description == 'EDGE boundary')\n",
    "        )[0])\n",
    "\n",
    "    print(\"Removing break annotations for the cropped raw...\")\n",
    "    raw_intensity_cropped.annotations.delete(np.where(\n",
    "        (raw_intensity_cropped.annotations.description == 'XStart_break') | \n",
    "        (raw_intensity_cropped.annotations.description == 'XStop_break') | \n",
    "        (raw_intensity_cropped.annotations.description == 'BAD boundary') | \n",
    "        (raw_intensity_cropped.annotations.description == 'EDGE boundary')\n",
    "        )[0])\n",
    "    \n",
    "    # Optical density and correction\n",
    "    print(\"Converting to optical density...\")\n",
    "    cropped_od = optical_density(raw_intensity_cropped)\n",
    "    original_od= optical_density(raw_intensity)\n",
    "\n",
    "    # Replace oversaturated channels with high variance noise\n",
    "\n",
    "    # Flag bad channels if standard deviation exceeds 15% - averaged signal over two wavelengths\n",
    "    \n",
    "    # Linearly nterpolate all flagged channels from adjacent good channels\n",
    "\n",
    "    # Motion artifact correction\n",
    "    print(\"Applying 'Temporal Derivative Distribution Repair' motion artefact correction...\")\n",
    "    cropped_corrected_od = temporal_derivative_distribution_repair(cropped_od)\n",
    "    original_corrected_od = temporal_derivative_distribution_repair(original_od)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing subject 05, session 01...\n",
      "Loading raw NIRS data from BIDS dataset format\n",
      "Reading 0 ... 8666  =      0.000 ...  1663.872 secs...\n",
      "Extracting event timings...\n",
      "Used Annotations descriptions: [np.str_('Xend'), np.str_('Xstart')]\n",
      "Used Annotations descriptions: [np.str_('Control'), np.str_('Noise'), np.str_('Speech'), np.str_('Xend'), np.str_('Xstart')]\n"
     ]
    }
   ],
   "source": [
    "root_bids\n",
    "save_path\n",
    "subject\n",
    "session\n",
    "\n",
    "raw_intensity_sub01_ses01 = signal_quality_single_subject(data_path=root_bids, save_path='', task=task, subject='05', session='01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mne",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
